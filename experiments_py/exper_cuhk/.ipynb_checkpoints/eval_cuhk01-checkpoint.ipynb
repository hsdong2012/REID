{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current work dir:/home/maochaojie/work/My_ReID\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "root = '../../'\n",
    "import os\n",
    "os.chdir(root)\n",
    "print 'current work dir:%s'%os.getcwd()\n",
    "caffe_root = 'caffe'  \n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + '/python')\n",
    "import caffe\n",
    "import random\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import time\n",
    "import pdb\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "from multiprocessing import Pool\n",
    "from threading import Thread\n",
    "import skimage.io\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_time(num_time):\n",
    "    seconds=num_time%60\n",
    "    minuites=num_time/60%60\n",
    "    hours=num_time/3600%24\n",
    "    days=num_time/3600/24\n",
    "    fm_time={'sec':seconds,'min':minuites,'hours':hours,'days':days}\n",
    "    return fm_time\n",
    "\n",
    "\n",
    "def processImageCrop(im_info, transformer, flow):\n",
    "    # print file_root\n",
    "    #im_path = './' + file_root + im_info[0]\n",
    "    im_path = im_info[0]\n",
    "    # print im_path\n",
    "    im_crop = im_info[1]\n",
    "    im_reshape = im_info[2]\n",
    "    im_flip = im_info[3]\n",
    "    data_in = caffe.io.load_image(im_path)\n",
    "\n",
    "    if (data_in.shape[0] < im_reshape[0]) | (data_in.shape[1] < im_reshape[1]):\n",
    "        data_in = caffe.io.resize_image(data_in, im_reshape)\n",
    "    if im_flip:\n",
    "        # data_in = caffe.io.flip_image(data_in, 1, flow)\n",
    "        data_in = data_in[im_crop[0]:im_crop[2], im_crop[1]:im_crop[3], :]\n",
    "    processed_image = transformer.preprocess('data_in', data_in)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "\n",
    "class ImageProcessorCrop(object):\n",
    "    def __init__(self, transformer, flow):\n",
    "        self.transformer = transformer\n",
    "        self.flow = flow\n",
    "        # print file_root\n",
    "\n",
    "    def __call__(self, im_info):\n",
    "        return processImageCrop(im_info, self.transformer, self.flow)\n",
    "\n",
    "\n",
    "class sequenceGeneratorVideo(object):\n",
    "    def __init__(self, buffer_size, clip_length, num_videos, video_dict, video_order):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.clip_length = clip_length\n",
    "        self.N = self.buffer_size * self.clip_length\n",
    "        self.num_videos = num_videos\n",
    "        self.video_dict = video_dict\n",
    "        self.video_order = video_order\n",
    "        self.idx = 0\n",
    "        # self.file_root = file_root\n",
    "        # print file_root\n",
    "\n",
    "    def __call__(self):\n",
    "        label_r = []\n",
    "        im_paths = []\n",
    "        im_paths_p = []\n",
    "        im_crop = []\n",
    "        im_reshape = []\n",
    "        im_flip = []\n",
    "\n",
    "        if self.idx + self.buffer_size >= self.num_videos:\n",
    "            idx_list = range(self.idx, self.num_videos)\n",
    "            idx_list.extend(range(0, self.buffer_size - (self.num_videos - self.idx)))\n",
    "        else:\n",
    "            idx_list = range(self.idx, self.idx + self.buffer_size)\n",
    "        print idx_list\n",
    "        \n",
    "        if self.video_dict['setting']['phase'] == 'train':    \n",
    "            for i in idx_list:\n",
    "                key = self.video_order[i]\n",
    "                label = self.video_dict[key]['label']\n",
    "                video_reshape = self.video_dict[key]['reshape']\n",
    "                video_crop = self.video_dict[key]['crop']\n",
    "                label_r.extend([label] * self.clip_length)\n",
    "\n",
    "                im_reshape.extend([(video_reshape)] * self.clip_length)\n",
    "                r0 = int(random.random() * (video_reshape[0] - video_crop[0]))\n",
    "                r1 = int(random.random() * (video_reshape[1] - video_crop[1]))\n",
    "                im_crop.extend([(r0, r1, r0 + video_crop[0], r1 + video_crop[1])] * self.clip_length)\n",
    "                f = random.randint(0, 1)\n",
    "                im_flip.extend([f] * self.clip_length)\n",
    "\n",
    "                # rand_frame = int(random.random()*(self.video_dict[key]['num_frames']-self.clip_length)+1+1)\n",
    "                # get the path of probe frames\n",
    "\n",
    "                frames = []\n",
    "\n",
    "                for i in range(0, self.clip_length):\n",
    "                    frames.append(self.video_dict[key]['frames'])\n",
    "                im_paths.extend(frames)\n",
    "\n",
    "                # get the path of view frames\n",
    "                frames_p = []\n",
    "                frames_buffer = []\n",
    "                for ii in range(self.video_dict[key]['start_frames'], self.video_dict[key]['end_frames'] + 1):\n",
    "                    frames_buffer.append(self.video_dict[key]['frames_p'] % ii)\n",
    "\n",
    "                for i in range(0, self.clip_length):\n",
    "                    frames_p.append(frames_buffer[i % len(frames_buffer)])\n",
    "                im_paths_p.extend(frames_p)\n",
    "        else:\n",
    "            if self.video_dict['setting']['phase'] == 'cmc':\n",
    "                for i in idx_list:\n",
    "                    key = self.video_order[i]\n",
    "                    label = self.video_dict[key]['label']\n",
    "                    video_reshape = self.video_dict[key]['reshape']\n",
    "                    video_crop = self.video_dict[key]['crop']\n",
    "                    label_r.extend([label] * self.clip_length)\n",
    "\n",
    "                    im_reshape.extend([(video_reshape)] * self.clip_length)\n",
    "                    r0 = int(random.random() * (video_reshape[0] - video_crop[0]))\n",
    "                    r1 = int(random.random() * (video_reshape[1] - video_crop[1]))\n",
    "                    im_crop.extend([(r0, r1, r0 + video_crop[0], r1 + video_crop[1])] * self.clip_length)\n",
    "                    f = random.randint(0, 1)\n",
    "                    im_flip.extend([f] * self.clip_length)\n",
    "\n",
    "                    # rand_frame = int(random.random()*(self.video_dict[key]['num_frames']-self.clip_length)+1+1)\n",
    "                    # get the path of probe frames\n",
    "\n",
    "                    frames = []\n",
    "\n",
    "                    for i in range(0, self.clip_length):\n",
    "                        frames.append(self.video_dict[key]['frames'][0])\n",
    "                    im_paths.extend(frames)\n",
    "\n",
    "                    # get the path of view frames\n",
    "                    frames_p = []\n",
    "                    frames_buffer = []\n",
    "                    frames_buffer.extend(self.video_dict[key]['frames_p'][0])\n",
    "                    #print frames_buffer\n",
    "\n",
    "                    for i in range(0, self.clip_length):\n",
    "                        frames_p.append(frames_buffer[i % len(frames_buffer)])\n",
    "                    im_paths_p.extend(frames_p)\n",
    "                    \n",
    "\n",
    "        # print im_paths\n",
    "        im_info = zip(im_paths, im_crop, im_reshape, im_flip)\n",
    "        im_info_p = zip(im_paths_p, im_crop, im_reshape, im_flip)\n",
    "        self.idx += self.buffer_size\n",
    "        if self.idx >= self.num_videos:\n",
    "            self.idx = self.idx - self.num_videos\n",
    "\n",
    "        return label_r, im_info, im_info_p\n",
    "\n",
    "\n",
    "def advance_batch(result, sequence_generator, image_processor, pool, clip_length):\n",
    "    label_r, im_info, im_info_p = sequence_generator()\n",
    "    #print im_info\n",
    "    #print im_info_p\n",
    "    result['data'] = pool.map(image_processor, im_info)\n",
    "    result['data_p'] = pool.map(image_processor, im_info_p)\n",
    "    result['label'] = label_r\n",
    "    cm = np.ones(len(label_r))\n",
    "    cm[0::clip_length] = 0\n",
    "    result['clip_markers'] = cm\n",
    "\n",
    "\n",
    "class BatchAdvancer():\n",
    "    def __init__(self, result, sequence_generator, image_processor, pool, clip_length):\n",
    "        self.result = result\n",
    "        self.sequence_generator = sequence_generator\n",
    "        self.image_processor = image_processor\n",
    "        self.pool = pool\n",
    "        self.clip_length = clip_length\n",
    "\n",
    "    def __call__(self):\n",
    "        return advance_batch(self.result, self.sequence_generator, self.image_processor, self.pool, self.clip_length)\n",
    "\n",
    "\n",
    "class videoRead(object):\n",
    "    def initialize(self, phase, flow_flag, video_batch, video_length, channels, height, width, path_root, video_list='./'):\n",
    "        self.train_or_test = phase\n",
    "        self.flow = flow_flag\n",
    "        self.buffer_size = video_batch  # num videos processed per batch\n",
    "        self.frames = video_length  # length of processed clip\n",
    "        self.N = self.buffer_size * self.frames\n",
    "        self.idx = 0\n",
    "        self.channels = channels\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.path_to_images = path_root # the pre path to the datasets\n",
    "        self.video_list = video_list\n",
    "    def readlistFromFile(self):\n",
    "        f = open(self.video_list, 'r')\n",
    "        f_lines = f.readlines()\n",
    "        # print f_lines\n",
    "        f.close()\n",
    "        \n",
    "        video_dict = {}\n",
    "        current_line = 0\n",
    "        self.video_order = []\n",
    "        c = 0\n",
    "        print \"data list is loading...\"\n",
    "        video_dict['setting'] = {}\n",
    "        video_dict['setting']['phase'] = 'train'\n",
    "        for ix, line in enumerate(f_lines):\n",
    "            if c== 0:\n",
    "                imgname_length = len(line.split(' ')[0].split('/')[-1])\n",
    "                videoname_length = len(line.split(' ')[1])\n",
    "                viewname_length = imgname_length - videoname_length - 4\n",
    "                print imgname_length\n",
    "                print videoname_length\n",
    "                print viewname_length\n",
    "                \n",
    "            path_to_img = line.split(' ')[0][:-imgname_length] #dataset/cuhk01/cuhk01/\n",
    "            video = line.split(' ')[0].split('/')[-1][0:videoname_length]  # 0377\n",
    "            #self.file_root = path_to_img + '/'\n",
    "            # print video\n",
    "            l = int(line.split(' ')[4])\n",
    "            frames = glob.glob('%s%s%s*.png' % (self.path_to_images, path_to_img, video))\n",
    "            num_frames = len(frames)\n",
    "            # print num_frames\n",
    "            # print frames\n",
    "            # random key\n",
    "            key_timeseed = random.randint(0, 1000)\n",
    "            videokey = video + '%d' % (ix % 1000) + '%d' % random.randint(0, 10) + '%d' % key_timeseed\n",
    "            video_dict[videokey] = {}\n",
    "            # print (frames[0].split('/')[2].split('.')[0] + '.%04d.jpg')\n",
    "            \n",
    "            video_dict[videokey]['frames'] = line.split(' ')[0]  # should verify\n",
    "            video_dict[videokey]['frames_p'] = path_to_img+line.split(' ')[1] + '%0'+'%d'%viewname_length+'d.png' # should verify\n",
    "            video_dict[videokey]['reshape'] = (160, 80)\n",
    "            video_dict[videokey]['crop'] = (160, 80)\n",
    "            video_dict[videokey]['start_frames'] = int(line.split(' ')[2])\n",
    "            video_dict[videokey]['end_frames'] = int(line.split(' ')[3])\n",
    "            video_dict[videokey]['num_frames'] = int(line.split(' ')[3]) - int(line.split(' ')[2]) + 1\n",
    "            video_dict[videokey]['label'] = l\n",
    "            self.video_order.append(videokey)\n",
    "            c += 1\n",
    "            if c % 10000 == 0:\n",
    "                print \"data list is loading %d\" % c\n",
    "            if c%50 == 0:\n",
    "                break\n",
    "        print \"data list loading finished..\"\n",
    "        self.video_dict = video_dict\n",
    "        self.num_videos = len(video_dict.keys())-1\n",
    "        print len(video_dict)\n",
    "    def readlistFromPairs(self, image, sequence, seq_key):\n",
    "        video_dict = {}\n",
    "        current_line = 0\n",
    "        self.video_order = []\n",
    "        c = 0\n",
    "        #print \"data list is loading...\"\n",
    "        #probe_length = len(probe)\n",
    "        #gallerys_length = len(gallerys)\n",
    "        #if not probe_length == gallerys_length:\n",
    "        #    print \"error: id number is not matched between probe and gallerys\"\n",
    "        #else:\n",
    "        video_dict['setting'] = {}\n",
    "        video_dict['setting']['phase'] = 'cmc'\n",
    "        videokey = seq_key\n",
    "        video_dict[videokey] = {}\n",
    "        video_dict[videokey]['frames'] = image  # should verify\n",
    "        video_dict[videokey]['frames_p'] = sequence  # should verify\n",
    "        video_dict[videokey]['reshape'] = (160, 80)\n",
    "        video_dict[videokey]['crop'] = (160, 80)\n",
    "        video_dict[videokey]['label'] = 1\n",
    "        self.video_order.append(videokey)\n",
    "        #print video_dict\n",
    "        #print \"data list loading finished..\"\n",
    "        self.video_dict = video_dict\n",
    "        self.num_videos = len(video_dict.keys())-1\n",
    "        #print len(video_dict)\n",
    "    def readlistFromList(self, probe, gallerys):\n",
    "        video_dict = {}\n",
    "        current_line = 0\n",
    "        self.video_order = []\n",
    "        c = 0\n",
    "        print \"data list is loading...\"\n",
    "        probe_length = len(probe)\n",
    "        gallerys_length = len(gallerys)\n",
    "        if not probe_length == gallerys_length:\n",
    "            print \"error: id number is not matched between probe and gallerys\"\n",
    "        else:\n",
    "            video_dict['setting'] = {}\n",
    "            video_dict['setting']['phase'] = 'cmc'\n",
    "            for key in gallerys:\n",
    "                videokey = key\n",
    "                video_dict[videokey] = {}\n",
    "                \n",
    "                video_dict[videokey]['frames'] = probe[key]  # should verify\n",
    "                video_dict[videokey]['frames_p'] = gallerys[key]  # should verify\n",
    "                video_dict[videokey]['reshape'] = (160, 80)\n",
    "                video_dict[videokey]['crop'] = (160, 80)\n",
    "                video_dict[videokey]['label'] = 1\n",
    "                self.video_order.append(videokey)\n",
    "                c += 1\n",
    "                if c % 100 == 0:\n",
    "                    print \"data list is loading %d\" % c\n",
    "                if c%50 == 0:\n",
    "                    break\n",
    "        print \"data list loading finished..\"\n",
    "        \n",
    "        self.video_dict = video_dict\n",
    "        self.num_videos = len(video_dict.keys())-1\n",
    "        print len(video_dict)\n",
    "\n",
    "    def setup(self):\n",
    "        # print video_dict\n",
    "        # set up data transformer\n",
    "        shape = (self.N, self.channels, self.height, self.width)\n",
    "\n",
    "        self.transformer = caffe.io.Transformer({'data_in': shape})\n",
    "        self.transformer.set_raw_scale('data_in', 255)\n",
    "        if self.flow:\n",
    "            image_mean = [128, 128, 128]\n",
    "            # self.transformer.set_is_flow('data_in', True)\n",
    "        else:\n",
    "            image_mean = [104.00698793, 116.66876762, 122.67891434]\n",
    "            # self.transformer.set_is_flow('data_in', False)\n",
    "        channel_mean = np.zeros((3, 160, 80))\n",
    "        for channel_index, mean_val in enumerate(image_mean):\n",
    "            channel_mean[channel_index, ...] = mean_val\n",
    "        self.transformer.set_mean('data_in', channel_mean)\n",
    "        self.transformer.set_channel_swap('data_in', (2, 1, 0))\n",
    "        self.transformer.set_transpose('data_in', (2, 0, 1))\n",
    "\n",
    "        self.thread_result = {}\n",
    "        self.thread = None\n",
    "        pool_size = self.buffer_size\n",
    "\n",
    "        self.image_processor = ImageProcessorCrop(self.transformer, self.flow)\n",
    "        self.sequence_generator = sequenceGeneratorVideo(self.buffer_size, self.frames, self.num_videos,\n",
    "                                                         self.video_dict, self.video_order)\n",
    "\n",
    "        self.pool = Pool(processes=pool_size)\n",
    "        self.batch_advancer = BatchAdvancer(self.thread_result, self.sequence_generator, self.image_processor,\n",
    "                                            self.pool, self.frames)\n",
    "        self.dispatch_worker()\n",
    "        self.top_names = ['data', 'data_p', 'label', 'clip_markers']\n",
    "        print 'Outputs:', self.top_names\n",
    "        self.join_worker()\n",
    "        \n",
    "    def forward(self, net):\n",
    "        if self.thread is not None:\n",
    "            self.join_worker()\n",
    "        # rearrange the data: The LSTM takes inputs as [video0_frame0, video1_frame0,...] but the data is currently arranged as [video0_frame0, video0_frame1, ...]\n",
    "        # label_r, im_info=self.sequenceGeneratorInstance.sequenceGenerator()\n",
    "        # print label_r\n",
    "        # print im_info\n",
    "        new_result_data = [None] * len(self.thread_result['data'])\n",
    "        new_result_data_p = [None] * len(self.thread_result['data_p'])\n",
    "        new_result_label = [None] * len(self.thread_result['label'])\n",
    "        new_result_cm = [None] * len(self.thread_result['clip_markers'])\n",
    "        \n",
    "        for i in range(self.frames):\n",
    "            for ii in range(self.buffer_size):\n",
    "                old_idx = ii * self.frames + i\n",
    "                new_idx = i * self.buffer_size + ii\n",
    "                new_result_data[new_idx] = self.thread_result['data'][old_idx]\n",
    "                new_result_data_p[new_idx] = self.thread_result['data_p'][old_idx]\n",
    "                new_result_label[new_idx] = self.thread_result['label'][old_idx]\n",
    "                new_result_cm[new_idx] = self.thread_result['clip_markers'][old_idx]\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            net.blobs['data'].data[i, ...] = new_result_data[i]\n",
    "            net.blobs['data_p'].data[i, ...] = new_result_data_p[i]\n",
    "\n",
    "        net.blobs['label'].data[...] = new_result_label\n",
    "        net.blobs['clip_markers'].data[...] = new_result_cm\n",
    "        if self.num_videos > 1:\n",
    "            self.dispatch_worker()\n",
    "\n",
    "    def dispatch_worker(self):\n",
    "        assert self.thread is None\n",
    "        self.thread = Thread(target=self.batch_advancer)\n",
    "        self.thread.start()\n",
    "\n",
    "    def join_worker(self):\n",
    "        assert self.thread is not None\n",
    "        self.thread.join()\n",
    "        self.thread = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readList(name_list,name_dict,sequence_flag): \n",
    "    import random\n",
    "    import os\n",
    "    probes = {}\n",
    "    gallerys = {}\n",
    "    if sequence_flag == False:\n",
    "        \n",
    "        for key in name_list:\n",
    "            length = len(name_dict[key][:])\n",
    "            probe_index = random.randint(0,length-1)\n",
    "            if not probes.has_key(key):\n",
    "                probes[key] = []\n",
    "            probes[key].append(name_dict[key][probe_index])\n",
    "            gallery_index = random.randint(0,length-1)\n",
    "            while probe_index == gallery_index:\n",
    "                gallery_index = random.randint(0,length-1)\n",
    "            if not gallerys.has_key(key):\n",
    "                gallerys[key] = []\n",
    "            gallerys[key].append(name_dict[key][gallery_index])\n",
    "    else:\n",
    "        for key in name_list:\n",
    "            length = len(name_dict[key][:])\n",
    "            probe_index = random.randint(0,length-1)\n",
    "            if not probes.has_key(key):\n",
    "                probes[key] = []\n",
    "            probes[key].append(name_dict[key][probe_index])\n",
    "            buffer = []\n",
    "            buffer = name_dict[key][:]\n",
    "            del buffer[probe_index]\n",
    "            if not gallerys.has_key(key):\n",
    "                gallerys[key] = []\n",
    "            gallerys[key].append(buffer) \n",
    "        \n",
    "    if len(probes)!=len(gallerys):\n",
    "        print('something wrong! list length does not match!/n')\n",
    "        return 0\n",
    "    else:\n",
    "        return probes,gallerys\n",
    "def generatePredictList(net, data_operator, probes, gallerys):\n",
    "    from time import clock\n",
    "    start=clock()\n",
    "    predictLists = []\n",
    "    key_probe = probes.keys()\n",
    "    key_gallerys = gallerys.keys()\n",
    "    for key in key_probe:\n",
    "        predict = []\n",
    "        for keys in key_gallerys:\n",
    "            #print probes[key]\n",
    "            #print gallerys[keys]\n",
    "            data_operator.readlistFromPairs(probes[key],gallerys[keys],keys)\n",
    "            data_operator.setup()\n",
    "            data_operator.forward(net)\n",
    "            net.forward()\n",
    "            #print \"wrong\"\n",
    "            outScore=net.blobs['softmax_score'].data.reshape((16,2))\n",
    "            #print outScore\n",
    "            similarScore=outScore[15,1]\n",
    "            print similarScore\n",
    "            predict.append(similarScore)\n",
    "        predictRanklist=np.argsort(-predict)\n",
    "        predictLists.append(predictLists)\n",
    "        print predictRanklist\n",
    "    finish=clock()\n",
    "    print('\\r  Processing %dx%d pairs cost %f second time'%(len(probes),len(gallerys),(finish-start)))\n",
    "    return predictLists,key_probe,key_gallery\n",
    "\n",
    "def calCMC(net,set_no,rand_times=10):\n",
    "    from cmc import evaluateCMC\n",
    "    #rand 10 times for stable result\n",
    "    cmc_list=[]\n",
    "    for i in range(rand_times):\n",
    "        print 'Round %d with rand list:'%i\n",
    "        probes,gallerys=readList(list_name)\n",
    "        scoreList,predictLists=generateScoreList(net,probes,gallerys)\n",
    "        gtLabels=range(len(probes))\n",
    "        cmc=evaluateCMC(gtLabels,predictLists)\n",
    "        cmc_list.append(cmc)\n",
    "    return np.average(cmc_list,axis=0)\n",
    "\n",
    "def getCVPRcmc():\n",
    "    #return the cmc values, 100 dim vetor\n",
    "    import numpy as np\n",
    "    cmcIndex=[0,4,8,12,16,21,25,29,33,37,41,45,49,53]\n",
    "    cmcOfCVPRImproved=[0.5474,0.8753,0.9293,0.9712,0.9764,0.9811,0.9899,0.9901,0.9912,0.9922,0.9937,0.9945,0.9951,1]\n",
    "    pOfCVPRImproved = np.poly1d(np.polyfit(cmcIndex,cmcOfCVPRImproved,10))\n",
    "    x_line=range(50)\n",
    "    cmc=pOfCVPRImproved(x_line)\n",
    "    return cmc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR='dataset/cuhk01/cuhk01/'\n",
    "file_list_a=os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971\n",
      "['dataset/cuhk01/cuhk01/0003001.png', 'dataset/cuhk01/cuhk01/0003003.png', 'dataset/cuhk01/cuhk01/0003002.png', 'dataset/cuhk01/cuhk01/0003004.png']\n"
     ]
    }
   ],
   "source": [
    "name_dict={}\n",
    "\n",
    "for name in file_list_a:\n",
    "    if name[-3:]=='png':\n",
    "        id = name[:4]\n",
    "        if not name_dict.has_key(id):\n",
    "            name_dict[id]=[]\n",
    "        name_dict[id].append(DATA_DIR+name)  \n",
    "\n",
    "print len(name_dict)\n",
    "print name_dict['0003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/cuhk01/exp_set/testid486_set01_test.txt\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "# choose test ids:\n",
    "test_id_number = 486\n",
    "set_no = 1\n",
    "phase = 'test'\n",
    "filename_test = 'dataset/cuhk01/exp_set/testid%03d_set%02d_%s.txt'%(test_id_number,(set_no),phase)\n",
    "print filename_test\n",
    "\n",
    "file_object = open(filename_test)\n",
    "try:\n",
    "    all_the_text = file_object.read( )\n",
    "finally:\n",
    "    file_object.close( )\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "lines = all_the_text.split('\\n')\n",
    "for filename in lines:\n",
    "    if filename!='':\n",
    "        if name_dict.has_key(filename):\n",
    "            test_dict[filename] = name_dict[filename]\n",
    "print len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmcDict={}\n",
    "cmc_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/cuhk01/exp_set/testid486_set01_test.txt\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "# choose test ids:\n",
    "test_id_number = 486\n",
    "set_no = 1\n",
    "phase = 'test'\n",
    "filename_test = 'dataset/cuhk01/exp_set/testid%03d_set%02d_%s.txt'%(test_id_number,(set_no),phase)\n",
    "print filename_test\n",
    "\n",
    "file_object = open(filename_test)\n",
    "try:\n",
    "    all_the_text = file_object.read( )\n",
    "finally:\n",
    "    file_object.close( )\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "lines = all_the_text.split('\\n')\n",
    "for filename in lines:\n",
    "    if filename!='':\n",
    "        if name_dict.has_key(filename):\n",
    "            test_dict[filename] = name_dict[filename]\n",
    "print len(test_dict)\n",
    "key_list = []\n",
    "for key in test_dict.keys():\n",
    "    key_list.append(key)\n",
    "\n",
    "key_list_shuffle = key_list[:]\n",
    "random.shuffle(key_list_shuffle)\n",
    "probes,gallerys=readList(key_list_shuffle[:],test_dict,True)#\n",
    "#print probes\n",
    "#print gallerys\n",
    "#print len(key_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0835', '0834', '0836', '0833', '0832', '0839', '0838', '0131', '0545', '0544', '0546', '0541', '0939', '0428', '0542', '0934', '0935', '0936', '0937', '0931', '0932', '0933', '0398', '0808', '0722', '0724', '0727', '0729', '0681', '0686', '0338', '0339', '0805', '0332', '0333', '0331', '0337', '0334', '0335', '0116', '0117', '0114', '0051', '0054', '0370', '0109', '0754', '0204', '0205', '0750', '0203', '0200', '0753', '0617', '0616', '0758', '0610', '0613', '0269', '0938', '0540', '0543', '0424', '0425', '0868', '0970', '0878', '0871', '0259', '0873', '0421', '0875', '0877', '0876', '0509', '0508', '0140', '0501', '0502', '0504', '0506', '0488', '0147', '0480', '0481', '0482', '0486', '0487', '0475', '0471', '0809', '0378', '0379', '0376', '0377', '0806', '0807', '0373', '0802', '0803', '0579', '0575', '0576', '0577', '0570', '0572', '0573', '0394', '0395', '0396', '0390', '0258', '0392', '0393', '0255', '0254', '0257', '0251', '0399', '0199', '0653', '0652', '0655', '0657', '0656', '0718', '0719', '0895', '0894', '0893', '0891', '0713', '0899', '0022', '0023', '0020', '0217', '0025', '0028', '0216', '0190', '0664', '0665', '0624', '0625', '0621', '0098', '0097', '0096', '0195', '0093', '0629', '0091', '0159', '0311', '0840', '0841', '0842', '0843', '0845', '0847', '0848', '0849', '0531', '0532', '0533', '0535', '0929', '0537', '0539', '0925', '0437', '0436', '0697', '0696', '0690', '0699', '0327', '0326', '0320', '0288', '0287', '0285', '0282', '0283', '0445', '0443', '0265', '0260', '0262', '0263', '0105', '0106', '0101', '0100', '0102', '0669', '0198', '0744', '0743', '0741', '0740', '0661', '0662', '0191', '0196', '0197', '0749', '0748', '0583', '0066', '0067', '0064', '0062', '0063', '0060', '0118', '0963', '0962', '0961', '0967', '0964', '0968', '0499', '0493', '0497', '0169', '0494', '0793', '0798', '0400', '0402', '0405', '0407', '0409', '0815', '0814', '0813', '0811', '0568', '0563', '0161', '0561', '0153', '0228', '0386', '0384', '0222', '0623', '0918', '0226', '0388', '0919', '0708', '0318', '0319', '0314', '0315', '0090', '0310', '0910', '0313', '0135', '0039', '0038', '0132', '0133', '0035', '0034', '0037', '0030', '0032', '0670', '0756', '0637', '0636', '0143', '0632', '0631', '0146', '0202', '0639', '0853', '0852', '0850', '0857', '0856', '0858', '0521', '0520', '0527', '0526', '0529', '0911', '0916', '0917', '0880', '0350', '0354', '0355', '0356', '0291', '0888', '0293', '0295', '0294', '0297', '0889', '0596', '0597', '0594', '0595', '0593', '0590', '0458', '0457', '0599', '0178', '0179', '0273', '0272', '0271', '0270', '0170', '0172', '0177', '0185', '0184', '0186', '0181', '0180', '0182', '0189', '0188', '0772', '0771', '0777', '0775', '0778', '0779', '0004', '0005', '0006', '0001', '0002', '0008', '0009', '0073', '0075', '0359', '0959', '0957', '0954', '0296', '0950', '0783', '0782', '0781', '0787', '0786', '0789', '0412', '0411', '0410', '0417', '0416', '0415', '0414', '0418', '0558', '0559', '0360', '0551', '0556', '0554', '0277', '0239', '0238', '0276', '0233', '0232', '0231', '0237', '0235', '0736', '0737', '0734', '0735', '0732', '0733', '0730', '0738', '0739', '0306', '0305', '0304', '0303', '0049', '0125', '0123', '0042', '0043', '0045', '0047', '0879', '0602', '0603', '0600', '0607', '0604', '0926', '0560', '0387', '0229', '0921', '0225', '0904', '0903', '0867', '0864', '0862', '0908', '0860', '0516', '0517', '0510', '0511', '0667', '0365', '0340', '0346', '0349', '0348', '0580', '0468', '0582', '0587', '0589', '0588', '0460', '0461', '0466', '0467', '0242', '0243', '0240', '0168', '0246', '0245', '0163', '0248', '0249', '0166', '0165', '0164', '0646', '0647', '0644', '0645', '0391', '0649', '0884', '0885', '0887', '0769', '0881', '0882', '0883', '0764', '0767', '0761', '0760', '0016', '0015', '0012', '0088', '0084', '0087', '0080', '0082', '0949', '0944', '0947', '0946', '0700', '0706']\n"
     ]
    }
   ],
   "source": [
    "key_probe = probes.keys()\n",
    "print key_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0835', '0834', '0836', '0833', '0832', '0839', '0838', '0131', '0545', '0544', '0546', '0541', '0939', '0428', '0542', '0934', '0935', '0936', '0937', '0931', '0932', '0933', '0398', '0808', '0722', '0724', '0727', '0729', '0681', '0686', '0338', '0339', '0805', '0332', '0333', '0331', '0337', '0334', '0335', '0116', '0117', '0114', '0051', '0054', '0370', '0109', '0754', '0204', '0205', '0750', '0203', '0200', '0753', '0617', '0616', '0758', '0610', '0613', '0269', '0938', '0540', '0543', '0424', '0425', '0868', '0970', '0878', '0871', '0259', '0873', '0421', '0875', '0877', '0876', '0509', '0508', '0140', '0501', '0502', '0504', '0506', '0488', '0147', '0480', '0481', '0482', '0486', '0487', '0475', '0471', '0809', '0378', '0379', '0376', '0377', '0806', '0807', '0373', '0802', '0803', '0579', '0575', '0576', '0577', '0570', '0572', '0573', '0394', '0395', '0396', '0390', '0258', '0392', '0393', '0255', '0254', '0257', '0251', '0399', '0199', '0653', '0652', '0655', '0657', '0656', '0718', '0719', '0895', '0894', '0893', '0891', '0713', '0899', '0022', '0023', '0020', '0217', '0025', '0028', '0216', '0190', '0664', '0665', '0624', '0625', '0621', '0098', '0097', '0096', '0195', '0093', '0629', '0091', '0159', '0311', '0840', '0841', '0842', '0843', '0845', '0847', '0848', '0849', '0531', '0532', '0533', '0535', '0929', '0537', '0539', '0925', '0437', '0436', '0697', '0696', '0690', '0699', '0327', '0326', '0320', '0288', '0287', '0285', '0282', '0283', '0445', '0443', '0265', '0260', '0262', '0263', '0105', '0106', '0101', '0100', '0102', '0669', '0198', '0744', '0743', '0741', '0740', '0661', '0662', '0191', '0196', '0197', '0749', '0748', '0583', '0066', '0067', '0064', '0062', '0063', '0060', '0118', '0963', '0962', '0961', '0967', '0964', '0968', '0499', '0493', '0497', '0169', '0494', '0793', '0798', '0400', '0402', '0405', '0407', '0409', '0815', '0814', '0813', '0811', '0568', '0563', '0161', '0561', '0153', '0228', '0386', '0384', '0222', '0623', '0918', '0226', '0388', '0919', '0708', '0318', '0319', '0314', '0315', '0090', '0310', '0910', '0313', '0135', '0039', '0038', '0132', '0133', '0035', '0034', '0037', '0030', '0032', '0670', '0756', '0637', '0636', '0143', '0632', '0631', '0146', '0202', '0639', '0853', '0852', '0850', '0857', '0856', '0858', '0521', '0520', '0527', '0526', '0529', '0911', '0916', '0917', '0880', '0350', '0354', '0355', '0356', '0291', '0888', '0293', '0295', '0294', '0297', '0889', '0596', '0597', '0594', '0595', '0593', '0590', '0458', '0457', '0599', '0178', '0179', '0273', '0272', '0271', '0270', '0170', '0172', '0177', '0185', '0184', '0186', '0181', '0180', '0182', '0189', '0188', '0772', '0771', '0777', '0775', '0778', '0779', '0004', '0005', '0006', '0001', '0002', '0008', '0009', '0073', '0075', '0359', '0959', '0957', '0954', '0296', '0950', '0783', '0782', '0781', '0787', '0786', '0789', '0412', '0411', '0410', '0417', '0416', '0415', '0414', '0418', '0558', '0559', '0360', '0551', '0556', '0554', '0277', '0239', '0238', '0276', '0233', '0232', '0231', '0237', '0235', '0736', '0737', '0734', '0735', '0732', '0733', '0730', '0738', '0739', '0306', '0305', '0304', '0303', '0049', '0125', '0123', '0042', '0043', '0045', '0047', '0879', '0602', '0603', '0600', '0607', '0604', '0926', '0560', '0387', '0229', '0921', '0225', '0904', '0903', '0867', '0864', '0862', '0908', '0860', '0516', '0517', '0510', '0511', '0667', '0365', '0340', '0346', '0349', '0348', '0580', '0468', '0582', '0587', '0589', '0588', '0460', '0461', '0466', '0467', '0242', '0243', '0240', '0168', '0246', '0245', '0163', '0248', '0249', '0166', '0165', '0164', '0646', '0647', '0644', '0645', '0391', '0649', '0884', '0885', '0887', '0769', '0881', '0882', '0883', '0764', '0767', '0761', '0760', '0016', '0015', '0012', '0088', '0084', '0087', '0080', '0082', '0949', '0944', '0947', '0946', '0700', '0706']\n"
     ]
    }
   ],
   "source": [
    "key_probe = gallerys.keys()\n",
    "print key_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_Imageroot = './'\n",
    "test_frames = 16\n",
    "test_buffer = 1\n",
    "\n",
    "video_testInstance = videoRead()\n",
    "video_testInstance.initialize('test', False, test_buffer, test_frames, 3, 160, 80, path_Imageroot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 with rand list:\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "Outputs:[0]\n",
      "['dataset/cuhk01/cuhk01/0835004.png', 'dataset/cuhk01/cuhk01/0835003.png', 'dataset/cuhk01/cuhk01/0835002.png']\n",
      " ['data', 'data_p', 'label', 'clip_markers']\n",
      "0.951946\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs: ['data', 'data_p', 'label', 'clip_markers']\n",
      "\n",
      "['dataset/cuhk01/cuhk01/0834003.png', 'dataset/cuhk01/cuhk01/0834001.png', 'dataset/cuhk01/cuhk01/0834004.png']\n",
      "9.34668e-05\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs: ['data', 'data_p', 'label', 'clip_markers']\n",
      "\n",
      "['dataset/cuhk01/cuhk01/0836004.png', 'dataset/cuhk01/cuhk01/0836002.png', 'dataset/cuhk01/cuhk01/0836003.png']\n",
      "0.012007\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs: ['data', 'data_p', 'label', 'clip_markers']\n",
      "\n",
      "['dataset/cuhk01/cuhk01/0833003.png', 'dataset/cuhk01/cuhk01/0833002.png', 'dataset/cuhk01/cuhk01/0833001.png']\n",
      "2.49821e-05\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs: ['data', 'data_p', 'label', 'clip_markers']\n",
      "\n",
      "['dataset/cuhk01/cuhk01/0832002.png', 'dataset/cuhk01/cuhk01/0832001.png', 'dataset/cuhk01/cuhk01/0832004.png']\n",
      "7.49505e-06\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs: ['data', 'data_p', 'label', 'clip_markers']\n",
      "\n",
      "['dataset/cuhk01/cuhk01/0839002.png', 'dataset/cuhk01/cuhk01/0839003.png', 'dataset/cuhk01/cuhk01/0839004.png']\n",
      "0.00257392\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs: ['data', 'data_p', 'label', 'clip_markers']\n",
      "\n",
      "['dataset/cuhk01/cuhk01/0838001.png', 'dataset/cuhk01/cuhk01/0838004.png', 'dataset/cuhk01/cuhk01/0838002.png']\n",
      "2.08629e-05\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "Outputs:[0]\n",
      "['dataset/cuhk01/cuhk01/0131002.png', 'dataset/cuhk01/cuhk01/0131003.png', 'dataset/cuhk01/cuhk01/0131004.png']\n",
      " ['data', 'data_p', 'label', 'clip_markers']\n",
      "3.80816e-05\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs: ['data', 'data_p', 'label', 'clip_markers']\n",
      "\n",
      "['dataset/cuhk01/cuhk01/0545004.png', 'dataset/cuhk01/cuhk01/0545003.png', 'dataset/cuhk01/cuhk01/0545001.png']\n",
      "0.00984482\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs:\n",
      "['dataset/cuhk01/cuhk01/0544001.png', 'dataset/cuhk01/cuhk01/0544002.png', 'dataset/cuhk01/cuhk01/0544003.png']\n",
      " ['data', 'data_p', 'label', 'clip_markers']\n",
      "0.000105992\n",
      "data list is loading...\n",
      "data list loading finished..\n",
      "[0]Outputs: ['data', 'data_p', 'label', 'clip_markers']\n",
      "\n",
      "['dataset/cuhk01/cuhk01/0546004.png', 'dataset/cuhk01/cuhk01/0546003.png', 'dataset/cuhk01/cuhk01/0546002.png']\n",
      "3.69744e-06\n",
      "data list is loading...\n",
      "data list loading finished..\n"
     ]
    }
   ],
   "source": [
    "cmc_root = './experiments/common_tools'\n",
    "sys.path.insert(0,cmc_root)\n",
    "from cmc import evaluateCMC\n",
    "DEPLOY_PATH= 'models/ourNet/lstm_16frames/deploy.prototxt'\n",
    "LSTM_MODELPATH = 'models/Snapshots/lstm_16frames_model/snapshots_lstm_RGB_iter_100000.caffemodel'\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Net(DEPLOY_PATH, LSTM_MODELPATH, caffe.TEST)\n",
    "for i in range(7):\n",
    "    print 'Round %d with rand list:'%i\n",
    "    key_list_shuffle = key_list[:]\n",
    "    random.shuffle(key_list_shuffle)\n",
    "    probes,gallerys=readList(key_list_shuffle[:],name_dict,True)\n",
    "    predictLists, key_probes, key_gallerys =generatePredictList(net,video_testInstance,probes,gallerys)\n",
    "    cmc=evaluateCMC(predictLists, key_probes, key_gallerys)\n",
    "    cmc_list.append(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print np.average(cmc_list[:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmc_all = np.average(cmc_list[10:20],axis=0)\n",
    "print cmc_all\n",
    "cmcDict['ours (GN, no hnm)'] = cmc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmc_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose test ids:\n",
    "test_id_number = 100\n",
    "set_no = 1\n",
    "phase = 'test'\n",
    "filename_test = '../../dataset/cuhk01/exp_set/testid%03d_set%02d_%s.txt'%(test_id_number,(set_no),phase)\n",
    "print filename_test\n",
    "\n",
    "file_object = open(filename_test)\n",
    "try:\n",
    "    all_the_text = file_object.read( )\n",
    "finally:\n",
    "    file_object.close( )\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "lines = all_the_text.split('\\n')\n",
    "for filename in lines:\n",
    "    if filename!='':\n",
    "        if name_dict.has_key(filename):\n",
    "            test_dict[filename] = name_dict[filename]\n",
    "print len(test_dict)\n",
    "key_list = []\n",
    "for key in test_dict.keys():\n",
    "    key_list.append(key)\n",
    "\n",
    "key_list_shuffle = key_list[:]\n",
    "random.shuffle(key_list_shuffle)\n",
    "probes,gallerys=readList(key_list_shuffle[:],test_dict)\n",
    "print len(key_list)\n",
    "from cmc import evaluateCMC\n",
    "MODEL_FILE = '../../experiments/reid_earlyfusion_google_cuhk01/set01/deploy.prototxt'\n",
    "PRETRAINED = '../../experiments/reid_earlyfusion_google_cuhk01/set01/Snapshots/set01_round3_iter_12586.caffemodel'\n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE, PRETRAINED,caffe.TEST)\n",
    "for i in range(10):\n",
    "    print 'Round %d with rand list:'%i\n",
    "    key_list_shuffle = key_list[:]\n",
    "    random.shuffle(key_list_shuffle)\n",
    "    probes,gallerys=readList(key_list_shuffle[:],name_dict)\n",
    "    scoreList,predictLists=generateScoreList(net,probes,gallerys)\n",
    "    gtLabels=range(len(probes))\n",
    "    cmc=evaluateCMC(gtLabels,predictLists)\n",
    "    cmc_list.append(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmc_all = np.average(cmc_list[:],axis=0)\n",
    "print cmc_all\n",
    "cmcDict['ours (GN, hnm)'] = cmc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmcDict={}\n",
    "import scipy.io as sio\n",
    "data = sio.loadmat('/mnt/share/Temp/reid_mat/cuhk01_100ID.mat')['data']\n",
    "from eval_cuhk03 import plotCMC\n",
    "\n",
    "cmcDict['ImprovedDL'] = data[0]\n",
    "cmcDict['KISSME'] = data[1]\n",
    "# cmcDict['eSDC'] = data[2]\n",
    "#cmcDict['SDALF'] = data[3]\n",
    "cmcDict['LDM'] = data[4]\n",
    "#cmcDict['RANK'] = data[5]\n",
    "cmcDict['LMNN'] = data[6]\n",
    "#cmcDict['ITML'] = data[7]\n",
    "#cmcDict['Euclid'] = data[8]\n",
    "cmcDict['FPNN'] = data[9]\n",
    "cmcDict['DCSL (GN, hnm)']=load_list['ours (GN, hnm)']\n",
    "cmcDict['DCSL (GN, no hnm)']=load_list['ours (GN, no hnm)']\n",
    "#plot the dictionary, sorted by rank1 rate\n",
    "\n",
    "save_path = 'cuhk01_id100_set01.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotCMC(cmcDict,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "cmcDict_bk = cmcDict\n",
    "f1 = open(\"res_cuhk01_100id.txt\",\"wb\")\n",
    "pickle.dump(cmcDict, f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from eval_cuhk03 import plotCMC\n",
    "f2 = open(\"res_cuhk01_100id.txt\",\"rb\")\n",
    "load_list = pickle.load(f2)\n",
    "f2.close()\n",
    "save_path = '../../paper/cuhk01_100ID.png'\n",
    "plotCMC(load_list,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import scipy.io as sio\n",
    "\n",
    "load_dict = dict(load_list)\n",
    "\n",
    "data = sio.loadmat('/mnt/share/Temp/reid_mat/cuhk01_100ID.mat')['data']\n",
    "\n",
    "load_dict['ImprovedDL'] = data[0]\n",
    "load_dict['KISSME'] = data[1]\n",
    "# cmcDict['eSDC'] = data[2]\n",
    "#cmcDict['SDALF'] = data[3]\n",
    "load_dict['LDM'] = data[4]\n",
    "#cmcDict['RANK'] = data[5]\n",
    "load_dict['LMNN'] = data[6]\n",
    "#cmcDict['ITML'] = data[7]\n",
    "#cmcDict['Euclid'] = data[8]\n",
    "load_dict['FPNN'] = data[9]\n",
    "\n",
    "methods = ['ours (GN, hnm)','ImprovedDL','KISSME','FPNN','LDM']\n",
    "table = []\n",
    "for mtd in methods:\n",
    "    this_list = []\n",
    "    this_list.append(mtd)\n",
    "    this_list.append(load_dict[mtd][0]*100)\n",
    "    this_list.append(load_dict[mtd][1]*100)\n",
    "    this_list.append(load_dict[mtd][4]*100)\n",
    "    this_list.append(load_dict[mtd][9]*100)\n",
    "    table.append(this_list)\n",
    "\n",
    "print table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print tabulate(table,headers=[\"Method\",\"r = 1\", \"r = 2\", \"r = 5\", \"r = 10\"], tablefmt=\"latex\",floatfmt=\".2f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
